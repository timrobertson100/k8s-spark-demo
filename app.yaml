---
apiVersion: spark.stackable.tech/v1alpha1
kind: SparkApplication
metadata:
  name: spark-hive-demo-app
spec:
  version: "1.0"
  sparkImage: docker.stackable.tech/stackable/spark-k8s:3.4.0-stackable23.7.0
  mode: cluster
  # How to point to a jar file in HDFS
  mainApplicationFile: hdfs://gbif-hdfs/tmp/spark-hive-demo-1.0.0-3.4.0.jar
  # Example on how to point to a downloadable file on a fileserver
  # mainApplicationFile: https://download.gbif.org/tim/spark-hive-demo-1.0.0-3.3.0.jar
  mainClass: org.gbif.demo.SparkHiveDemoApp
  args:
    - "dev2.occurrence"
    - "dev2.delme"
  sparkConf:
    "spark.driver.extraJavaOptions": "-XX:+UseConcMarkSweepGC"
    "spark.executor.extraJavaOptions": "-XX:+UseConcMarkSweepGC"
    "spark.broadcast.compress": "true"
    "spark.checkpoint.compress": "true"
    "spark.io.compression.codec": "lz4"
    "spark.rdd.compress": "true"
    "spark.driver.extraClassPath": "/dependencies/jars/*"
    "spark.executor.extraClassPath": "/dependencies/jars/*"
    "spark.driver.extraClassPath": "/etc/hadoop/conf/"
    "spark.executor.extraClassPath": "/etc/hadoop/conf/"
  # The following config maps are managed in our K8s environment using GBIF naming convention
  volumes:
  - name: hadoop-env
    configMap:
      name: gbif-hdfs
      items:
        - key: core-site.xml
          path: core-site.xml
        - key: hdfs-site.xml
          path: hdfs-site.xml
  - name: hive-env
    configMap:
      name: gbif-hive-metastore-custom
      items:
        - key: hive-site.xml
          path: hive-site.xml
  driver:
    resources:
      cpu:
        min: "1"
        max: "4"
      memory:
        limit: "2Gi"
    # Mount the GBIF-managed volumes providing environment configuration for Spark
    volumeMounts:
    - name: hadoop-env
      mountPath: /etc/hadoop/conf/core-site.xml
      subPath: core-site.xml
    - name: hadoop-env
      mountPath: /etc/hadoop/conf/hdfs-site.xml
      subPath: hdfs-site.xml
    - name: hive-env
      mountPath: /etc/hadoop/conf/hive-site.xml
      subPath: hive-site.xml

  executor:
    instances: 5
    resources:
      cpu:
        min: "1"
        max: "6"
      memory:
        limit: "10Gi"
    # Mount the GBIF-managed volumes providing environment configuration for Spark
    volumeMounts:
    - name: hadoop-env
      mountPath: /etc/hadoop/conf/core-site.xml
      subPath: core-site.xml
    - name: hadoop-env
      mountPath: /etc/hadoop/conf/hdfs-site.xml
      subPath: hdfs-site.xml
    - name: hive-env
      mountPath: /etc/hadoop/conf/hive-site.xml
      subPath: hive-site.xml