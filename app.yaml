---
apiVersion: spark.stackable.tech/v1alpha1
kind: SparkApplication
metadata:
  name: spark-hive-demo-app
spec:
  version: "1.0"
  sparkImage: docker.stackable.tech/stackable/spark-k8s:3.3.0-stackable0.1.0
  mode: cluster
  # How to point to a jar file in HDFS
  mainApplicationFile: hdfs://gbif-hdfs/tmp/spark-hive-demo-1.0.0-3.3.0.jar
  # Example on how to point to a downloadable file on a fileserver
  # mainApplicationFile: https://download.gbif.org/tim/spark-hive-demo-1.0.0-3.3.0.jar
  mainClass: org.gbif.demo.SparkHiveDemoApp
  # Example of providing application arguments
  #  args:
  #    - "thrift://gbif-hive-metastore-metastore-default-0.gbif-hive-metastore-metastore-default.stack-demo.svc.cluster.local:9083"
  #    - "mySourceTable"
  #    - "myTargetTable"
  sparkConf:
    "spark.driver.extraJavaOptions": "-XX:+UseConcMarkSweepGC"
    "spark.executor.extraJavaOptions": "-XX:+UseConcMarkSweepGC"
    "spark.broadcast.compress": "true"
    "spark.checkpoint.compress": "true"
    "spark.io.compression.codec": "lz4"
    "spark.rdd.compress": "true"
    "spark.driver.extraClassPath": "/dependencies/jars/*"
    "spark.executor.extraClassPath": "/dependencies/jars/*"
    "spark.driver.extraClassPath": "/etc/hadoop/conf/"
    "spark.executor.extraClassPath": "/etc/hadoop/conf/"
  # The following config maps are managed in our K8s environment using GBIF naming convention
  volumes:
  - name: hadoop-env
    configMap:
      name: gbif-hdfs
      items:
        - key: core-site.xml
          path: core-site.xml
        - key: hdfs-site.xml
          path: hdfs-site.xml
  - name: hive-env
    configMap:
      name: gbif-hive-metastore-metastore-default
      items:
        - key: hive-site.xml
          path: hive-site.xml
  driver:
    resources:
      cpu:
        min: "1"
        max: "4"
      memory:
        limit: "2Gi"
    # Mount the GBIF-managed volumes providing environment configuration for Spark
    volumeMounts:
    - name: hadoop-env
      mountPath: /etc/hadoop/conf/core-site.xml
      subPath: core-site.xml
    - name: hadoop-env
      mountPath: /etc/hadoop/conf/hdfs-site.xml
      subPath: hdfs-site.xml
    - name: hive-env
      mountPath: /etc/hadoop/conf/hive-site.xml
      subPath: hive-site.xml

  executor:
    instances: 5
    resources:
      cpu:
        min: "1"
        max: "6"
      memory:
        limit: "10Gi"
    # Mount the GBIF-managed volumes providing environment configuration for Spark
    volumeMounts:
    - name: hadoop-env
      mountPath: /etc/hadoop/conf/core-site.xml
      subPath: core-site.xml
    - name: hadoop-env
      mountPath: /etc/hadoop/conf/hdfs-site.xml
      subPath: hdfs-site.xml
    - name: hive-env
      mountPath: /etc/hadoop/conf/hive-site.xml
      subPath: hive-site.xml